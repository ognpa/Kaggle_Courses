{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7ae612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038a5895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  \n",
       "0                9  \n",
       "1               11  \n",
       "2               12  \n",
       "3                4  \n",
       "4               20  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_ingredients']=data.ingredients.apply(lambda x:len(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1506d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "irish            9.299850\n",
       "brazilian        9.520343\n",
       "southern_us      9.634954\n",
       "british          9.708955\n",
       "japanese         9.735067\n",
       "french           9.817838\n",
       "italian          9.909033\n",
       "filipino        10.000000\n",
       "greek           10.182128\n",
       "russian         10.224949\n",
       "spanish         10.423660\n",
       "mexican         10.877446\n",
       "korean          11.284337\n",
       "chinese         11.982791\n",
       "jamaican        12.214829\n",
       "thai            12.545809\n",
       "cajun_creole    12.617076\n",
       "vietnamese      12.675152\n",
       "indian          12.705961\n",
       "moroccan        12.909866\n",
       "Name: num_ingredients, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('cuisine').num_ingredients.mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb0d242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3c5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import regexp_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "pd.set_option('display.width', 1000)\n",
    "data['recipe']=data.ingredients.apply(lambda x:', '.join([(i.lower()) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dffdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['recipe']=data.ingredients.apply(lambda x:', '.join([SnowballStemmer(language='english').stem(i.lower()) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a01eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indian'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Given a set of ingredients find probability it is a particular cuisine\n",
    "def find_probability_of_cuisine(lst,df):\n",
    "    df['num_count']=df.ingredients.apply(lambda x:len(set(x).intersection(set(lst))))\n",
    "    cross_t=pd.crosstab(df.cuisine,df.num_count).apply(lambda r: 100*r/r.sum(), axis=0)\n",
    "#So maybe having multiple combinations 1s 2s and 3s of ingredients identify it best cartersian product of all the combinatinos\n",
    "    reqd_df=pd.DataFrame(cross_t[len(lst)-1])\n",
    "    reqd_df.columns=['perc']\n",
    "    return reqd_df.perc.idxmax()\n",
    "\n",
    "find_probability_of_cuisine(['garlic','onion','ginger','masala'],data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae58d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'italian'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_probability_of_cuisine(['garlic','onion','basil'],data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f4ebe648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39752x2974 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 760352 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "vectors=cv.fit_transform(data.recipe)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24927a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=vectors.todense(), columns=sorted(cv.vocabulary_))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349f4a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>recipe</th>\n",
       "      <th>num_count</th>\n",
       "      <th>2_ingredient</th>\n",
       "      <th>3_ingredient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>romaine lettuc, black ol, grape tomato, garlic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[(romaine lettuce, black olives), (romaine let...</td>\n",
       "      <td>[(romaine lettuce, black olives, grape tomatoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>plain flour, ground pepp, salt, tomato, ground...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(plain flour, ground pepper), (plain flour, s...</td>\n",
       "      <td>[(plain flour, ground pepper, salt), (plain fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>egg, pepper, salt, mayonais, cooking oil, gree...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(eggs, pepper), (eggs, salt), (eggs, mayonais...</td>\n",
       "      <td>[(eggs, pepper, salt), (eggs, pepper, mayonais...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>water, vegetable oil, wheat, salt</td>\n",
       "      <td>0</td>\n",
       "      <td>[(water, vegetable oil), (water, wheat), (wate...</td>\n",
       "      <td>[(water, vegetable oil, wheat), (water, vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>black pepp, shallot, cornflour, cayenne pepp, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[(black pepper, shallots), (black pepper, corn...</td>\n",
       "      <td>[(black pepper, shallots, cornflour), (black p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  num_ingredients                                             recipe  num_count                                       2_ingredient                                       3_ingredient\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...                9  romaine lettuc, black ol, grape tomato, garlic...          1  [(romaine lettuce, black olives), (romaine let...  [(romaine lettuce, black olives, grape tomatoe...\n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...               11  plain flour, ground pepp, salt, tomato, ground...          0  [(plain flour, ground pepper), (plain flour, s...  [(plain flour, ground pepper, salt), (plain fl...\n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...               12  egg, pepper, salt, mayonais, cooking oil, gree...          0  [(eggs, pepper), (eggs, salt), (eggs, mayonais...  [(eggs, pepper, salt), (eggs, pepper, mayonais...\n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]                4                  water, vegetable oil, wheat, salt          0  [(water, vegetable oil), (water, wheat), (wate...  [(water, vegetable oil, wheat), (water, vegeta...\n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...               20  black pepp, shallot, cornflour, cayenne pepp, ...          0  [(black pepper, shallots), (black pepper, corn...  [(black pepper, shallots, cornflour), (black p..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product,combinations\n",
    "data['2_ingredient']=data.ingredients.apply(lambda x:list(combinations(x,2)))\n",
    "data['3_ingredient']=data.ingredients.apply(lambda x:list(combinations(x,3)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70540d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'pepper', 'salt', 'sugar', 'black pepper', 'black salt',\n",
       "       'black sugar', 'pepper salt', 'pepper sugar', 'salt sugar'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StemmerTokenizer(object):\n",
    "    \"\"\"\n",
    "    Joins all ingredients together into a single string and provides\n",
    "    a list of stems of all words longer than 2 letters.\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pattern = r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b'\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "\n",
    "    def mapper(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "\n",
    "    def tokenizer(self, doc):\n",
    "        return [self.mapper(t) for t in regexp_tokenize(doc, pattern=self.pattern)]\n",
    "\n",
    "    def preprocessor(self, line):\n",
    "        return ' '.join(line).lower()\n",
    "    \n",
    "tok = StemmerTokenizer()\n",
    "tok.tokenizer(\n",
    "            tok.preprocessor([\n",
    "                'romaine lettuce', 'black olives', 'grape tomatoes',\n",
    "                'garlic', 'pepper', 'purple onion', 'seasoning',\n",
    "                'garbanzo beans', 'feta cheese crumbles'\n",
    "            ])\n",
    "        )\n",
    "\n",
    "\n",
    "class DupleTokenizer1(StemmerTokenizer):\n",
    "    def tokenizer(self,doc):\n",
    "        words = np.array([self.mapper(t) for t in regexp_tokenize(doc, pattern=self.pattern)])\n",
    "\n",
    "        arr_2=list(combinations(words,2))\n",
    "        \n",
    "        words = sorted(set(words))\n",
    "        all_w=[]\n",
    "        for i in arr_2:\n",
    "            (j,k)=i    \n",
    "            wrd=(j+' '+k)\n",
    "            all_w.append(wrd)\n",
    "            \n",
    "       \n",
    "        return np.hstack([words,np.array(all_w)])\n",
    "        \n",
    "\n",
    "    \n",
    "tok = DupleTokenizer1()\n",
    "tok.tokenizer(\n",
    "            tok.preprocessor([\n",
    "               'black', 'pepper', 'salt', 'sugar'\n",
    "            ])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e7122dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmerTokenizer(object):\n",
    "    \"\"\"\n",
    "    Joins all ingredients together into a single string and provides\n",
    "    a list of stems of all words longer than 2 letters.\n",
    "\n",
    "    Example:\n",
    "    >>> tok = StemmerTokenizer()\n",
    "    >>> tok.tokenizer(\n",
    "            tok.preprocessor([\n",
    "                'romaine lettuce', 'black olives', 'grape tomatoes',\n",
    "                'garlic', 'pepper', 'purple onion', 'seasoning',\n",
    "                'garbanzo beans', 'feta cheese crumbles'\n",
    "            ])\n",
    "        )\n",
    "    ['romain', 'lettuc', 'black', 'oliv', 'grape', 'tomato',\n",
    "     'garlic', 'pepper', 'purpl', 'onion', 'season',\n",
    "     'garbanzo', 'bean', 'feta', 'chees', 'crumbl']\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pattern = r'(?u)\\b[a-zA-Z_][a-zA-Z_]+\\b'\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "\n",
    "    def mapper(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "\n",
    "    def tokenizer(self, doc):\n",
    "        return [self.mapper(t) for t in regexp_tokenize(doc, pattern=self.pattern)]\n",
    "\n",
    "    def preprocessor(self, line):\n",
    "        return ' '.join(line).lower()\n",
    "class DupleTokenizer(StemmerTokenizer):\n",
    "    \"\"\"\n",
    "    Builds upon the StemmerTokenizer: after all words in a recipe are stemmed\n",
    "    they are grouped in all possible combinations of two words and added\n",
    "    to the words' list.\n",
    "    \n",
    "    Example (simplified):\n",
    "    >>> tok = DupleTokenizer()\n",
    "    >>> tok.tokenizer(\n",
    "            tok.preprocessor([\n",
    "                'sugar', 'salt', 'black pepper'\n",
    "            ])\n",
    "        )\n",
    "    ['black', 'pepper', 'salt', 'sugar',\n",
    "     'black pepper', 'black salt', 'black sugar', 'pepper salt', 'pepper sugar', 'salt sugar']\n",
    "    \"\"\"\n",
    "    def tokenizer(self, doc):\n",
    "        \n",
    "        def duple(words):\n",
    "            duples = []\n",
    "            i = 0\n",
    "            while i < len(words)-1:\n",
    "                j = i + 1\n",
    "                while j < len(words):\n",
    "                    duples.append('%s %s' % (words[i], words[j]))\n",
    "                    j += 1\n",
    "                i += 1\n",
    "            return np.array(duples)\n",
    "        \n",
    "        words = np.array([self.mapper(t) for t in regexp_tokenize(doc, pattern=self.pattern)])\n",
    "        words = sorted(set(words))\n",
    "        words = np.hstack([words, duple(words)])\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd06e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StemmerTokenizer (single words):          2598\n",
      "DupleTokenizer (single words and pairs):  439909\n"
     ]
    }
   ],
   "source": [
    "def features_count(tokenizer, df):\n",
    "    vect = CountVectorizer(\n",
    "        preprocessor=tokenizer().preprocessor,\n",
    "        tokenizer=tokenizer().tokenizer)\n",
    "    return len(vect.fit(df.ingredients).vocabulary_)\n",
    "\n",
    "# It takes around 40s on my machine\n",
    "data = pd.read_json('./train.json')\n",
    "print ('StemmerTokenizer (single words):         ', features_count(StemmerTokenizer, data))\n",
    "print ('DupleTokenizer (single words and pairs): ', features_count(DupleTokenizer1, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6835f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "tokenizerClass = DupleTokenizer\n",
    "# Parameters were previously found based on a 3-fold cross validation\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        preprocessor=tokenizerClass().preprocessor,\n",
    "        tokenizer=tokenizerClass().tokenizer,\n",
    "        stop_words='english',\n",
    "        max_df=1.0,\n",
    "        min_df=1,\n",
    "        binary=True,\n",
    "    )),\n",
    "    ('transformer', TfidfTransformer()),\n",
    "    ('classifier', LinearSVC(\n",
    "        C=0.78, penalty='l2', loss='squared_hinge', dual=True, max_iter=1000, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4237735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40c04060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes around 50s\n",
    "train = pd.read_json('./train.json')\n",
    "X_train = train['ingredients']\n",
    "y_train = train['cuisine']\n",
    "\n",
    "test = pd.read_json('./test.json')\n",
    "X_test = test['ingredients']\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "prediction = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb11bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.copy()\n",
    "submission['cuisine'] = prediction\n",
    "test1=submission\n",
    "submission.to_csv(\n",
    "    'submission.csv', index=False, quoting=3,\n",
    "    columns=['id', 'cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7826d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.to_csv(\"abc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407582e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
